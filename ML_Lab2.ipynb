{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSox6f54tBvq1Msj2B5Ua4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahdevansh28/ML/blob/main/ML_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsVzqTPomtbj",
        "outputId": "d540ad62-ca1a-4c00-b353-09dbaca4e772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:\n",
            "     Country  Age  Salary Purchased\n",
            "0    France   44   72000        No\n",
            "1     Spain   27   48000       Yes\n",
            "2   Germany   30   54000        No\n",
            "3     Spain   38   61000        No\n",
            "4   Germany   40   68000       Yes\n",
            "5    France   35   58000       Yes\n",
            "6     Spain   39   52000        No\n",
            "7    France   48   79000       Yes\n",
            "8   Germany   50   83000        No\n",
            "9    France   37   67000       Yes\n",
            "10    Spain   45   55000        No\n",
            "[[0.73913043 0.68571429]\n",
            " [0.         0.        ]\n",
            " [0.13043478 0.17142857]\n",
            " [0.47826087 0.37142857]\n",
            " [0.56521739 0.57142857]\n",
            " [0.34782609 0.28571429]\n",
            " [0.52173913 0.11428571]\n",
            " [0.91304348 0.88571429]\n",
            " [1.         1.        ]\n",
            " [0.43478261 0.54285714]\n",
            " [0.7826087  0.2       ]]\n",
            "[[ 0.68188156  0.79548755]\n",
            " [-1.81835082 -1.41513049]\n",
            " [-1.37713334 -0.86247598]\n",
            " [-0.2005534  -0.21771238]\n",
            " [ 0.09359159  0.42705121]\n",
            " [-0.64177088 -0.49403964]\n",
            " [-0.05348091 -1.04669415]\n",
            " [ 1.27017153  1.44025115]\n",
            " [ 1.56431652  1.80868749]\n",
            " [-0.34762589  0.33494213]\n",
            " [ 0.82895405 -0.77036689]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "datasets = pd.read_csv('sample_data/Data_for_Transformation.csv')\n",
        "print(\"Data:\\n\",datasets)\n",
        "\n",
        "X = datasets.iloc[:,:-1].values\n",
        "Y = datasets.iloc[:,-1].values\n",
        "#print(X)\n",
        "#print(Y)\n",
        "\n",
        "X_new = datasets.iloc[:,1:3].values\n",
        "#print(X_new)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_new)\n",
        "print(X_scaled)\n",
        "\n",
        "std = StandardScaler()\n",
        "X_std = std.fit_transform(X_new)\n",
        "print(X_std)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps for handling categorial data"
      ],
      "metadata": {
        "id": "8lDUK_xvsXON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "\n",
        "datasets = pd.read_csv('sample_data/Data_for_Categorical_Values.csv')\n",
        "#print(datasets)\n",
        "#print(datasets.describe())\n",
        "\n",
        "X = datasets.iloc[:,0:3].values\n",
        "Y = datasets.iloc[:,3].values\n",
        "#print(X)\n",
        "#print(Y)\n",
        "\n",
        "le = LabelEncoder()\n",
        "X[ : ,0] = le.fit_transform(X[ : ,0])\n",
        "print(X)\n",
        "\n",
        "#dummy = pd.get_dummies(datasets['Country'])\n",
        "#print(dummy)\n",
        "#datasets = datasets.drop(['Country','Purchased'],axis=1)\n",
        "#print(datasets)\n",
        "#datasets = pd.concat([dummy,datasets],axis=1)\n",
        "#print(datasets)\n",
        "\n",
        "onhotencoder = OneHotEncoder()\n",
        "x = onhotencoder.fit_transform(datasets.Country.values.reshape(-1,1)).toarray()\n",
        "print(x)\n",
        "\n",
        "\n",
        "dfOneHot = "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88IUooCBsfWL",
        "outputId": "2f4a7f8e-dd7c-4c99-8b95-8645f49c5813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 44 72000]\n",
            " [2 27 48000]\n",
            " [1 30 54000]\n",
            " [2 38 61000]\n",
            " [1 40 68000]\n",
            " [0 35 58000]\n",
            " [2 39 52000]\n",
            " [0 48 79000]\n",
            " [1 50 83000]\n",
            " [0 37 67000]\n",
            " [2 45 55000]]\n",
            "[[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    }
  ]
}